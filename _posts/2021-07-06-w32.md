---
title: GAN_Generative Adversarial Networks
categories: [writing] 
comments: true
---
<p><span style="border-bottom: 12px solid #dcf1fb; padding: 0 0 0 0.2em;">GAN: Generative Adversarial Networks (꼼꼼한 딥러닝 논문 리뷰와 코드 실습)   
수업을 참고하여 작성하였습니다</span></p>
<p><span style="border-bottom: 12px solid #dcf1fb; padding: 0 0 0 0.2em;">GAN: Generative Adversarial Networks</span></p>

<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>정의</title>
</head>
<body>

<pre>
</pre>

<p><span style="background: linear-gradient(to right, #ffa7a3, #5673bd); padding: 0.43em 1em; font-size: 19px; border-radius: 3px; color: #ffffff;">GAN: Generative Adversarial Networks</span></p>
<pre>
1. GAN
1) 확률분포 : 확률변수가 특정한 값을 가질 확률을 나타내는 함수
- 이산확률분포 : 확률변수 X의 개수를 정확히 셀 수 있을 때
- 연속확률분포 : 확률변수 X의 개수를 정확히 셀 수 없을 때
  (확률밀도함수 이용해 분포 표현) (연속적 값) (정규분포)
</pre>
</body>
</html>
<img src = "https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdefoec%2FbtqOhPcmToI%2FGzzpCJgUDxrK7WrHKqQQLk%2Fimg.png" alt = "Gan">

<pre>
1) 이미지 데이터에 대한 확률분포
: 이미지 데이터는 다차원 특징 공간의 한 점으로 표현
  (사람의 얼굴에 통계적인 평균치 존재)
: 이미지에서의 다양한 특징들이 각각의 확률 변수가 되는 분포

3) 생성 모델 (Generative Models)
: 실존하지 않지만 있을 법한 이미지를 생성할 수 있는 모델
: 이미지 데이터의 분포를 근사하는 모델 G를 만드는 것이 생성 모델의 목표
: 모델 G가 잘 동작한다는 의미는 원래 이미지들의 분포를 잘 모델링 한다

: 여러개의 변수에 대한 가능성 분포의 통계적 모델
: 새로운 데이터 인스턴스를 생성하는 구조
: 시간이 지나면서 생성 모델 G가 원본 데이터의 분포를 학습
</pre>

<pre>
4) Generative(생성자) & Discriminator(판별자)
</pre>
<img src = "https://diya-blogpost.s3.us-east-1.amazonaws.com/imgs_2019CV/1-%EC%88%98%EC%8B%9D1.png" alt = "Gan 수식">
<pre>
- Generative(생성자) : G(z) -> new data instance
  -> 하나의 노이즈 벡터인 z를 받아 새로운 이미지 인스턴트 만들기
- Discriminator(판별자) : D(x) -> probability : a sample came from the real
  distribution (Real 1 ~ Fake 0)
  -> 이미지 x를 받아서 얼마나 진짜같은지에 대한 확률값을 출력으로 나타냄

- 좌식 (여러 개의 데이터를 봅은다음 G에 넣고, 그 값에 로그 취해 평균값 구하기)
       (실제 데이터의 확률분포로, x는 그 중 샘플링한 데이터)
- 우식 (생성자는 노이즈벡터부터 입력받아 새로운 이미지 만들 수 있음)
       (z 하나의 노이즈를 랜덤 샘플링 한 뒤 그 노이즈를 생성 자취에 넣어서 가짜 이미지를 만든 다음, 
       그 가짜 이미지 뒤에 -를 붙이고 1더한후 로그 취해 평균값 구하기 )
- G(z) 생성자는 값을 낮추고자.
  자기가 만든 가짜 이미지가 판별자에 의해 진짜라고 인식 될 수 있도록,
  1을 말할 수 있도록 학습 진행
- D(x) 판별자는 값을 높이고자
</pre> 
<img src = "https://blog.kakaocdn.net/dn/bzbFXQ/btq1R8vihl6/utx29ixNSHy0XnzkHVRtTK/img.png">

<pre>
5) 기댓값 계산 방법
: 단순히 모든 데이터를 하나씩 확인하여 식에 대입한 뒤에 평균 계산
- Ex~p data(x)[logD(x)] : 원본 데이터 분포에서의 샘플 x를 봅아
  logD(x)의 기대값 계산
- Ez~pz(z)[log(1-D(G(z)))] : 노이즈 분포에서의 샘플 z를 뽑아
  log(1-D(G(z)))의 기대값 계산

: 기대값은 모든 사건에 대해 확률을 곱하면서 더하여 계산
  (x 사건, f(x) 확률 분포 함수)
- 이산확률변수에 대한 기대값
</pre>
<img src = "https://latex.codecogs.com/gif.latex?E%5BX%5D%20%3D%20%5Csum_%7Bi%7D%5E%7B%7Dx_%7Bi%7D%5Ccdot%20f%28x_%7Bi%7D%29">
<pre>
- 연속확률변수에 대한 기대값
</pre>
<img src = "https://latex.codecogs.com/gif.latex?E%5BX%5D%20%3D%20%5Cint%20x%5Ccdot%20f%28x%29dx">

<pre>
6) GAN의 수렴 과정
- Pg -> Pdata, D(G(z)) -> 1/2 (G(z)is not distinguishable by D)
</pre>
<img src = "https://image.slidesharecdn.com/gan-190723113406/95/gan-generative-adversarial-nets-9-638.jpg?cb=1563881671">

<pre>
7) 직접 코드 실행
</pre>
[참고코드](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice)
